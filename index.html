<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <title>alexalemi.com</title>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-153903138-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-153903138-1');
    </script>

    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="AlexAlemi.com" href="https://alexalemi.com/rss.xml" />

    <!-- Search Engine -->
    <meta name="description" content="Alexander A. Alemi, Research Scientist">
    <meta name="image" content="https://alexalemi.com/images/me_small.jpg">

    <!-- Schema.org for Google -->
    <meta itemprop="name" content="alexalemi.com">
    <meta itemprop="description" content="Alexander A. Alemi, Research Scientist">
    <meta itemprop="image" content="https://alexalemi.com/images/me_small.jpg">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="alexalemi.com">
    <meta name="twitter:description" content="Alexander A. Alemi, Research Scientist">
    <meta name="twitter:creator" content="alemi">
    <meta name="twitter:image:src" content="https://alexalemi.com/images/me_small.jpg">

    <!-- Open Graph general (Facebook, Pinterest & Google+) -->
    <meta name="og:title" content="alexalemi.com">
    <meta name="og:description" content="Alexander A. Alemi, Research Scientist">
    <meta name="og:image" content="https://alexalemi.com/images/me_small.jpg">
    <meta name="og:url" content="https://alexalemi.com">
    <meta name="og:site_name" content="alexalemi.com">
    <meta name="og:type" content="website">

    <!-- Fonts -->
    <script type="text/javascript">
        WebFontConfig = {
            google: { families: [ 'Muli', 'Lato' ] }
        };
        (function() {
            var wf = document.createElement('script');
            wf.src = ('https:' == document.location.protocol ? 'https' : 'http') + '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
            wf.type = 'text/javascript';
            wf.async = 'true';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(wf, s);
        })();
    </script>

    <!-- Inline CSS -->
    <style>
        /* Browser reset */
        html {
            box-sizing: border-box;
            line-height: 1.15;
            -webkit-text-size-adjust: 100%;
        }

        /* Variables */
        :root {
          --accent-color: #3685B5;  
          /* Dark Slate Gray */
          --default-color: #2B2D54;

          --em-color: #0471A6;
          --highlight-color: #5C9FB3;

          --alt-color: DimGray;
          /* offwhite */
          --bg-color: #fefefe;
        }

        *,
        *::before,
        *::after {
            box-sizing: inherit;
        }


        body {

            /* Nice light gray background to offset the text a little */
            background-color: var(--bg-color);
            color: var(--default-color);
            margin: 0 auto;
            max-width: 50em;

            /* System fonts as fallbacks */
            font-family: "Lato", sans-serif;
            line-height: 1.5;
            padding: 2em 1em;
            scroll-behavior: smooth;
        }

        h1,
        h2,
        strong {
            color: var(--default-color);
            font-family: "Muli", sans-serif;
        }

        h2 {
            margin-top: 1em;
        }

        a {
            color: var(--em-color);
        }

        a:hover {
            color: var(--highlight-color);
        }

        h2 a {
          text-decoration: none;
          color: var(--default-color);
        }

        .headshot {
            float: right;
            width: 14em;
            padding-left: 2em;
        }

        .headshot img {
            width: 100%;
        }

        @media (max-width: 650px) {
            .headshot {
                width: 10em;
            }
        }

        header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            flex-flow: row;
        }

        @media (max-width: 650px) {
            header {
                display: flex;
                align-items: baseline;
                flex-flow: column;
            }

            .social-links {
                margin-top: 0.5em;
            }
        }

        @media (max-width: 390px) {
            header {
                width: 8em;
            }

            .social-links {
                width: 8em;
            }
        }

        .social-links a {
            text-decoration: none;
        }

        svg {
            margin-left: 7px;
            margin-right: 7px;
            height: 25px;
            width: 25px;
        }

        svg path {
            fill: var(--accent-color);
        }

        section ul {
          list-style: none;
        }

        section ul li {
          margin: 0 0 1.3em 0;
          line-height: 1.5;
        }

        section ul li p {
          color: var(--alt-color);
          font-size: 0.8em;
          padding: none;
        }

        section ul li p date {
          color: var(--default-color);
          font-style: normal;
        }

        section ul li cite {
          font-style: normal;
        }
    </style>


</head>

<body>

    <!-- Headshot -->
    <div class="headshot">
        <a href="assets/images/me.jpg"><img src="assets/images/me_round.jpg" alt="Alex Alemi Headshot" title="Alex Alemi Headshot" /></a>
    </div>

    <!-- Header with social links -->
    <header>
        <h1 style="margin-top: 0px; margin-bottom: 4px">Alexander A. Alemi</h1>

        <div class="social-links">
            <a href="mailto:alex.alemi@gmail.com"> <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 36 24">
                    <g>
                        <path class="cls-1" d="M18,13.47,34.52.25A2.55,2.55,0,0,0,33.43,0H2.57a2.55,2.55,0,0,0-1.1.25Z"></path>
                        <path class="cls-1" d="M35.74,1.46l-.06.07L18.54,15.24a.86.86,0,0,1-1.07,0L.32,1.53.26,1.46A2.54,2.54,0,0,0,0,2.57V21.43A2.57,2.57,0,0,0,2.57,24H33.43A2.57,2.57,0,0,0,36,21.43V2.57A2.55,2.55,0,0,0,35.74,1.46Z"></path>
                    </g>
                </svg> </a>
                <a href="https://scholar.google.com/citations?user=68hTs9wAAAAJ" target="_blank"> <svg
                    xmlns="http://www.w3.org/2000/svg" width="260" height="300" viewBox="0 0 260 300">
                    <path d="M103.72829,298.88172 C76.34128,296.29847 55.07609,284.76559 45.35826,267.22554 C41.88286,260.95267 41.53217,259.17959 41.53217,247.88048 C41.53217,236.92091 41.98334,234.4643 45.32507,227.22802 C55.34292,205.5351 81.81566,191.58318 121.07774,187.30412 C128.8195,186.46036 135.15369,185.29711 135.15369,184.71913 C135.15369,184.14113 133.53332,181.17574 131.55287,178.12935 C128.28338,173.10012 127.95204,171.47589 127.95204,160.47801 L127.95204,148.36556 L120.66352,148.36613 C95.21126,148.36813 75.12542,136.82734 65.03001,116.40067 C61.35084,108.95637 60.18949,104.78799 59.59142,96.88019 L58.83097,86.82528 L29.89344,86.82528 L0.95591,86.82528 L44.15096,43.61534 L87.346,0.40541 L173.73232,0.40541 L260.11864,0.40541 L252.63063,7.97238 L245.14262,15.53935 L245.14262,26.8935 C245.14262,35.05352 245.64139,38.54221 246.91555,39.29476 C251.32526,41.89915 251.68958,45.81489 251.68958,90.60576 C251.68958,120.92264 251.21713,136.18648 250.21033,138.39615 C246.89693,145.66826 235.53195,145.66826 232.21855,138.39615 C230.12498,133.80126 230.16142,47.62569 232.25885,43.02226 C233.09461,41.18796 234.27307,39.68717 234.87763,39.68717 C235.4822,39.68717 235.97151,36.29911 235.96499,32.15816 L235.95319,24.62916 L216.93681,43.74684 C198.13874,62.64504 197.93843,62.9081 199.48873,66.66119 C200.35263,68.75261 201.07886,76.63301 201.10567,84.20649 C201.18037,105.2887 199.00077,109.8059 179.53153,128.9215 C163.79908,144.36813 161.34149,147.91827 161.34149,155.19815 C161.34149,159.77841 166.77833,165.59815 186.76371,182.41089 C200.69031,194.12665 207.39839,202.24827 210.82478,211.54212 C214.67985,221.99874 215.3643,230.71556 213.16028,241.28612 C205.02561,280.30018 159.69108,304.16036 103.72825,298.88172 L103.72829,298.88172 Z M147.82552,283.18755 C154.75843,282.26978 161.10718,280.35673 167.47343,277.26712 C182.12774,270.15523 188.86239,259.963 188.81001,244.97642 C188.75861,230.27494 182.21614,220.86779 161.11753,205.15845 L149.39848,196.43284 L134.74707,197.20777 C111.70669,198.42641 95.8907,203.69967 84.90527,213.8257 C76.58521,221.49484 73.60929,228.25646 73.62507,239.4555 C73.65787,262.75366 92.18981,279.06402 123.36916,283.23638 C134.11128,284.67388 136.63593,284.66884 147.82552,283.18758 L147.82552,283.18755 Z M151.85933,133.13328 C155.64618,131.31754 160.26234,127.84197 162.11749,125.40975 C175.33106,108.08587 168.93712,68.34304 149.51809,47.09552 C141.02561,37.80341 132.23698,33.87543 122.01307,34.80251 C102.63987,36.55921 91.52619,50.26903 91.51737,72.42196 C91.50517,103.13522 108.02842,131.43235 129.04142,136.68421 C135.22411,138.22947 144.11702,136.84554 151.85933,133.13328 Z"
                        transform="translate(-1)" /></svg> </a>

                        <a href="http://twitter.com/alemi" target="_blank">
                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="256px" height="209px"
                    viewBox="0 0 256 209" version="1.1" preserveAspectRatio="xMidYMid">
                    <g>
                        <path d="M256,25.4500259 C246.580841,29.6272672 236.458451,32.4504868 225.834156,33.7202333 C236.678503,27.2198053 245.00583,16.9269929 248.927437,4.66307685 C238.779765,10.6812633 227.539325,15.0523376 215.57599,17.408298 C205.994835,7.2006971 192.34506,0.822 177.239197,0.822 C148.232605,0.822 124.716076,24.3375931 124.716076,53.3423116 C124.716076,57.4586875 125.181462,61.4673784 126.076652,65.3112644 C82.4258385,63.1210453 43.7257252,42.211429 17.821398,10.4359288 C13.3005011,18.1929938 10.710443,27.2151234 10.710443,36.8402889 C10.710443,55.061526 19.9835254,71.1374907 34.0762135,80.5557137 C25.4660961,80.2832239 17.3681846,77.9207088 10.2862577,73.9869292 C10.2825122,74.2060448 10.2825122,74.4260967 10.2825122,74.647085 C10.2825122,100.094453 28.3867003,121.322443 52.413563,126.14673 C48.0059695,127.347184 43.3661509,127.988612 38.5755734,127.988612 C35.1914554,127.988612 31.9009766,127.659938 28.694773,127.046602 C35.3777973,147.913145 54.7742053,163.097665 77.7569918,163.52185 C59.7820257,177.607983 37.1354036,186.004604 12.5289147,186.004604 C8.28987161,186.004604 4.10888474,185.75646 0,185.271409 C23.2431033,200.173139 50.8507261,208.867532 80.5109185,208.867532 C177.116529,208.867532 229.943977,128.836982 229.943977,59.4326002 C229.943977,57.1552968 229.893412,54.8901664 229.792282,52.6381454 C240.053257,45.2331635 248.958338,35.9825545 256,25.4500259"></path>
                    </g>
                </svg>
            </a>

            <a href="http://github.com/alexalemi" target="_blank">
                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="256px" height="250px"
                    viewBox="0 0 256 250" version="1.1" preserveAspectRatio="xMidYMid">
                    <g>
                        <path d="M128.00106,0 C57.3172926,0 0,57.3066942 0,128.00106 C0,184.555281 36.6761997,232.535542 87.534937,249.460899 C93.9320223,250.645779 96.280588,246.684165 96.280588,243.303333 C96.280588,240.251045 96.1618878,230.167899 96.106777,219.472176 C60.4967585,227.215235 52.9826207,204.369712 52.9826207,204.369712 C47.1599584,189.574598 38.770408,185.640538 38.770408,185.640538 C27.1568785,177.696113 39.6458206,177.859325 39.6458206,177.859325 C52.4993419,178.762293 59.267365,191.04987 59.267365,191.04987 C70.6837675,210.618423 89.2115753,204.961093 96.5158685,201.690482 C97.6647155,193.417512 100.981959,187.77078 104.642583,184.574357 C76.211799,181.33766 46.324819,170.362144 46.324819,121.315702 C46.324819,107.340889 51.3250588,95.9223682 59.5132437,86.9583937 C58.1842268,83.7344152 53.8029229,70.715562 60.7532354,53.0843636 C60.7532354,53.0843636 71.5019501,49.6441813 95.9626412,66.2049595 C106.172967,63.368876 117.123047,61.9465949 128.00106,61.8978432 C138.879073,61.9465949 149.837632,63.368876 160.067033,66.2049595 C184.49805,49.6441813 195.231926,53.0843636 195.231926,53.0843636 C202.199197,70.715562 197.815773,83.7344152 196.486756,86.9583937 C204.694018,95.9223682 209.660343,107.340889 209.660343,121.315702 C209.660343,170.478725 179.716133,181.303747 151.213281,184.472614 C155.80443,188.444828 159.895342,196.234518 159.895342,208.176593 C159.895342,225.303317 159.746968,239.087361 159.746968,243.303333 C159.746968,246.709601 162.05102,250.70089 168.53925,249.443941 C219.370432,232.499507 256,184.536204 256,128.00106 C256,57.3066942 198.691187,0 128.00106,0 Z M47.9405593,182.340212 C47.6586465,182.976105 46.6581745,183.166873 45.7467277,182.730227 C44.8183235,182.312656 44.2968914,181.445722 44.5978808,180.80771 C44.8734344,180.152739 45.876026,179.97045 46.8023103,180.409216 C47.7328342,180.826786 48.2627451,181.702199 47.9405593,182.340212 Z M54.2367892,187.958254 C53.6263318,188.524199 52.4329723,188.261363 51.6232682,187.366874 C50.7860088,186.474504 50.6291553,185.281144 51.2480912,184.70672 C51.8776254,184.140775 53.0349512,184.405731 53.8743302,185.298101 C54.7115892,186.201069 54.8748019,187.38595 54.2367892,187.958254 Z M58.5562413,195.146347 C57.7719732,195.691096 56.4895886,195.180261 55.6968417,194.042013 C54.9125733,192.903764 54.9125733,191.538713 55.713799,190.991845 C56.5086651,190.444977 57.7719732,190.936735 58.5753181,192.066505 C59.3574669,193.22383 59.3574669,194.58888 58.5562413,195.146347 Z M65.8613592,203.471174 C65.1597571,204.244846 63.6654083,204.03712 62.5716717,202.981538 C61.4524999,201.94927 61.1409122,200.484596 61.8446341,199.710926 C62.5547146,198.935137 64.0575422,199.15346 65.1597571,200.200564 C66.2704506,201.230712 66.6095936,202.705984 65.8613592,203.471174 Z M75.3025151,206.281542 C74.9930474,207.284134 73.553809,207.739857 72.1039724,207.313809 C70.6562556,206.875043 69.7087748,205.700761 70.0012857,204.687571 C70.302275,203.678621 71.7478721,203.20382 73.2083069,203.659543 C74.6539041,204.09619 75.6035048,205.261994 75.3025151,206.281542 Z M86.046947,207.473627 C86.0829806,208.529209 84.8535871,209.404622 83.3316829,209.4237 C81.8013,209.457614 80.563428,208.603398 80.5464708,207.564772 C80.5464708,206.498591 81.7483088,205.631657 83.2786917,205.606221 C84.8005962,205.576546 86.046947,206.424403 86.046947,207.473627 Z M96.6021471,207.069023 C96.7844366,208.099171 95.7267341,209.156872 94.215428,209.438785 C92.7295577,209.710099 91.3539086,209.074206 91.1652603,208.052538 C90.9808515,206.996955 92.0576306,205.939253 93.5413813,205.66582 C95.054807,205.402984 96.4092596,206.021919 96.6021471,207.069023 Z"></path>
                    </g>
                </svg>
            </a>

            <a href="rss.xml" target="_blank">
                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="256px" height="250px"
                    viewBox="0 0 24 24" version="1.1" preserveAspectRatio="xMidYMid">
                    <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-12.832 20c-1.197 0-2.168-.969-2.168-2.165s.971-2.165 2.168-2.165 2.167.969 2.167 2.165-.97 2.165-2.167 2.165zm5.18 0c-.041-4.029-3.314-7.298-7.348-7.339v-3.207c5.814.041 10.518 4.739 10.561 10.546h-3.213zm5.441 0c-.021-7.063-5.736-12.761-12.789-12.792v-3.208c8.83.031 15.98 7.179 16 16h-3.211z"/>
                    </svg>
            </a>
        </div>
    </header>

    <!-- Bio and stuff -->
    <main>

        <p>
            I am a Senior Research Scientist at <a href="https://ai.google/research/people/104980/">Google</a>. My current focus is the intersection of Information Theory and Deep Learning.
            I got my Ph.D. in Theoretical Condensed Matter Physics at Cornell University,
            supervised by <a href="http://sethna.lassp.cornell.edu/">Jim Sethna</a>.
            I got my B.S. at Caltech, where I majored in Physics.
        </p>

    </main>

    <!-- Section navigation using anchors -->
    <nav style="margin-top: 1.5em;">
        <p>
            <strong>Jump to: </strong>
            <a href="#research">Research</a> |
            <a href="#writing">Writing</a> |
            <a href="#code">Code</a> |
            <a href="#talks">Talks</a> |
            <!-- <a href="#poster-presentations">Poster Presentations</a> | -->
            <a href="#etc">Etc.</a>
        </p>
    </nav>

    <!-- Publications section -->
    <section id="research">
        <h2><a href="#research">Research</a></h2>


        <ul>
        
            <li>
             <cite>A Closer Look at the Adversarial Robustness of Information Bottleneck Models</cite>
             
             
                 <a href="publications/robustness.pdf">[pdf]</a>
             
             
             <p>
               I Korshunova, D Stutz, AA Alemi, O Wiles, S Gowal
               <date>2021-06</date>
               <strong>ICML 2021 AML Workshop Poster</strong>
             </p>
             <p>
               Looking more carefully, IB models aren't fully robust to adversarial examples.
             </p>
            </li>
        
            <li>
             <cite>Does Knowledge Distillation Really Work?</cite>
             
                 <a href="https://arxiv.org/abs/2106.05945">[arxiv]</a>
             
             
                 <a href="publications/distillation.pdf">[pdf]</a>
             
             
             <p>
               S Stanton, P Izmailov, P Kirichenko, AA Alemi, AG Wilson
               <date>2021-06</date>
               <strong></strong>
             </p>
             <p>
               Knowledge distillation doesn't seem to work as well as people assume it does.
             </p>
            </li>
        
            <li>
             <cite>VIB is Half Bayes</cite>
             
                 <a href="https://arxiv.org/abs/2011.08711">[arxiv]</a>
             
             
                 <a href="publications/pacvib.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, WR Morningstar, B Poole, I Fischer, JV Dillon
               <date>2020-11</date>
               <strong>AABI 2021 Oral</strong>
             </p>
             <p>
               VIB can be rederived as a half-Bayesian half-Maximum likelihood method.
             </p>
            </li>
        
            <li>
             <cite>PACᵐ-Bayes: Narrowing the Empirical Risk Gap in the Misspecified Bayesian Regime</cite>
             
                 <a href="https://arxiv.org/abs/2010.09629">[arxiv]</a>
             
             
                 <a href="publications/pacm.pdf">[pdf]</a>
             
             
             <p>
               WR Morningstar, AA Alemi, JV Dillon
               <date>2020-10</date>
               <strong></strong>
             </p>
             <p>
               Multisample bound that does better than Bayes at prediction for misspecified models.
             </p>
            </li>
        
            <li>
             <cite>Density of States Estimation for Out-of-Distribution Detection</cite>
             
                 <a href="https://arxiv.org/abs/2006.09273">[arxiv]</a>
             
             
                 <a href="publications/dose.pdf">[pdf]</a>
             
             
             <p>
               WR Morningstar, C Ham, AG Gallagher, B Lakshminarayanan, AA Alemi, JV Dillon
               <date>2020-06</date>
               <strong>AISTATS 2021 Oral</strong>
             </p>
             <p>
               Simple density-of-states inspired out of distribution detection.
             </p>
            </li>
        
            <li>
             <cite>The OpenKIM Processing Pipeline: A Cloud-Based Automatic Materials Property Computation Engine</cite>
             
                 <a href="https://arxiv.org/abs/2005.09062">[arxiv]</a>
             
             
                 <a href="publications/openkim.pdf">[pdf]</a>
             
             
                 <a href="https://openkim.org">[openkim.org]</a>
             
             <p>
               DS Karls, M Bierbaum, AA Alemi, RS Elliot, JP Sethna, EB Tadmor
               <date>2020-05</date>
               <strong>Journal of Chemical Physics</strong>
             </p>
             <p>
               Database for Interatomic Potentials.
             </p>
            </li>
        
            <li>
             <cite>Neural Tangents: Fast and Easy Infinite Neural Networks in Python</cite>
             
                 <a href="https://arxiv.org/abs/1912.02803">[arxiv]</a>
             
             
                 <a href="publications/neural_tangents.pdf">[pdf]</a>
             
             
                 <a href="https://github.com/google/neural-tangents">[code]</a>
             
             <p>
               R Novak, L Xiao, J Hron, J Lee, AA Alemi, J Sohl-Dickstein, SS Schoenholz
               <date>2019-12</date>
               <strong>ICLR</strong>
             </p>
             <p>
               Simple to use python package for training infinitely wide neural networks.
             </p>
            </li>
        
            <li>
             <cite>Variational Predictive Information Bottleneck</cite>
             
                 <a href="https://arxiv.org/abs/1910.10831">[arxiv]</a>
             
             
                 <a href="publications/pib.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi
               <date>2019-10</date>
               <strong>AABI</strong>
             </p>
             <p>
               Most modern inference procedures can be rederived as a simple variational bound on a predictive information bottleneck objective.
             </p>
            </li>
        
            <li>
             <cite>Information in Infinite Ensembles of Infinitely-Wide Networks</cite>
             
                 <a href="https://arxiv.org/abs/1911.09189">[arxiv]</a>
             
             
                 <a href="publications/infiniteinfo.pdf">[pdf]</a>
             
             
             <p>
               R Shwartz-Ziv, AA Alemi
               <date>2019-10</date>
               <strong>AABI</strong>
             </p>
             <p>
               While they seem complex, infinite ensembles of infinitely-wide networks are simple enough to enable tractable calculations of many information theoretic quantities.
             </p>
            </li>
        
            <li>
             <cite>CEB Improves Model Robustness</cite>
             
                 <a href="https://arxiv.org/abs/2002.05380">[arxiv]</a>
             
             
                 <a href="publications/cebrobust.pdf">[pdf]</a>
             
             
             <p>
               I Fischer, AA Alemi
               <date>2019-10</date>
               <strong>Entropy</strong>
             </p>
             <p>
               A class conditional version of VIB shows good robustness.
             </p>
            </li>
        
            <li>
             <cite>On Predictive Information in RNNs</cite>
             
                 <a href="https://arxiv.org/abs/1910.09578">[arxiv]</a>
             
             
                 <a href="publications/salamander.pdf">[pdf]</a>
             
             
             <p>
               Z Dong, D Oktay, B Poole, AA Alemi
               <date>2019-10</date>
               <strong></strong>
             </p>
             <p>
               Modern RNNs do not optimally capture predictive information in sequences.
             </p>
            </li>
        
            <li>
             <cite>Thermodynamic Computing</cite>
             
                 <a href="https://arxiv.org/abs/1911.01968">[arxiv]</a>
             
             
                 <a href="publications/thermodynamic.pdf">[pdf]</a>
             
             
             <p>
               T Conte, E DeBenedictis, N Ganesh, T Hylton, JP Strachan, RS Williams, AA Alemi, L Altenberg, G Crooks, J Crutchfield, L del Rio, J Deutsch, M DeWeese, K Douglas, M Esposito, M Frank, R Fry, P Harsha, M Hill, C Kello, J Krichmar, S Kumar, SC Liu, S Lloyd, M Marsili, I Nemenman, A Nugent, N Packard, D Randall, P Sadowski, N Santhanam, R Shaw, A Stieg, E Stopnitzky, C Teuscher, C Watkins, D Wolpert, J Yang, Y Yufik
               <date>2019-11</date>
               <strong>CCC</strong>
             </p>
             <p>
               A position paper on the future of thermodynamic computing.
             </p>
            </li>
        
            <li>
             <cite>On Variational Bounds of Mutual Information</cite>
             
                 <a href="https://arxiv.org/abs/1905.06922">[arxiv]</a>
             
             
                 <a href="publications/vmibounds.pdf">[pdf]</a>
             
             
             <p>
               B Poole, S Ozair, A van den Oord, AA Alemi, G Tucker
               <date>2019-05</date>
               <strong>ICML</strong>
             </p>
             <p>
               Overview of recent advances in variationally bounding mutual information.
             </p>
            </li>
        
            <li>
             <cite>Dueling Decoders: Regularizing Variational Autoencoder Latent Spaces</cite>
             
                 <a href="https://arxiv.org/abs/1905.07478">[arxiv]</a>
             
             
                 <a href="publications/dueling.pdf">[pdf]</a>
             
             
             <p>
               B Seybold, E Fertig, AA Alemi, I Fischer
               <date>2019-05</date>
               <strong></strong>
             </p>
             <p>
               Sometimes a worse decoder gives better representations.
             </p>
            </li>
        
            <li>
             <cite>Variational Autoencoders with Tensorflow Probability Layers</cite>
             
             
             
                 <a href="https://medium.com/tensorflow/variational-autoencoders-with-tensorflow-probability-layers-d06c658931b7">[post]</a>
             
             <p>
               I Fischer, AA Alemi, JV Dillon, TFP Team
               <date>2019-03</date>
               <strong>Tensorflow Blog</strong>
             </p>
             <p>
               TFP makes VAEs easy.
             </p>
            </li>
        
            <li>
             <cite>On the Use of ArXiv as a Dataset</cite>
             
                 <a href="https://arxiv.org/abs/1905.0075">[arxiv]</a>
             
             
                 <a href="publications/arxiv.pdf">[pdf]</a>
             
             
                 <a href="https://github.com/mattbierbaum/arxiv-public-datasets">[code]</a>
             
             <p>
               CB Clement, M Bierbaum, KP O'Keeffe, AA Alemi
               <date>2019-05</date>
               <strong>ICLR workshop RLGM</strong>
             </p>
             <p>
               More people should use the ArXiv as a dataset.
             </p>
            </li>
        
            <li>
             <cite>β-VAEs can retain label information even at high compression</cite>
             
                 <a href="https://arxiv.org/abs/1812.02682">[arxiv]</a>
             
             
                 <a href="publications/beta_retain.pdf">[pdf]</a>
             
             
             <p>
               E Fertig, A Arbabi, AA Alemi
               <date>2018-12</date>
               <strong>NeurIPS BDL Workshop</strong>
             </p>
             <p>
               Some rich decoder VAEs can magically focus on salient information.
             </p>
            </li>
        
            <li>
             <cite>Canonical Sectors and Evolution of Firms in the US Stock Markets</cite>
             
                 <a href="https://arxiv.org/abs/1503.06205">[arxiv]</a>
             
             
                 <a href="publications/stocks.pdf">[pdf]</a>
             
             
             <p>
               LX Hayden, R Chachra, AA Alemi, PH Ginsparg, JP Sethna
               <date>2018-10</date>
               <strong>Quantitative Finance</strong>
             </p>
             <p>
               Matrix factorization gives automatic and continous sector assignments to stocks.
             </p>
            </li>
        
            <li>
             <cite>WAIC, but Why? Generative Ensembles for Robust Anomaly Detection</cite>
             
                 <a href="https://arxiv.org/abs/1810.01392">[arxiv]</a>
             
             
                 <a href="publications/waic.pdf">[pdf]</a>
             
             
             <p>
               H Choi, E Jang, AA Alemi
               <date>2018-10</date>
               <strong></strong>
             </p>
             <p>
               Even though it shouldn't work, robust likelihoods can detect OOD data in practice.
             </p>
            </li>
        
            <li>
             <cite>TherML: Thermodynamics of Machine Learning</cite>
             
                 <a href="https://arxiv.org/abs/1807.04162">[arxiv]</a>
             
             
                 <a href="publications/therml.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, I Fisher
               <date>2018-07</date>
               <strong>ICML2018 TFADGM Workshop</strong>
             </p>
             <p>
               Modern variational latent variable modelling looks a lot like Thermodynamics.
             </p>
            </li>
        
            <li>
             <cite>Uncertainty in the Variational Information Bottleneck</cite>
             
                 <a href="https://arxiv.org/abs/1807.00906">[arxiv]</a>
             
             
                 <a href="publications/uncert_vib.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, I Fischer, JV Dillon
               <date>2018-07</date>
               <strong>UAI UDL Workshop</strong>
             </p>
             <p>
               VIB builds robust classifiers which are aware of what they don't know.
             </p>
            </li>
        
            <li>
             <cite>Watch your step: Learning node embeddings via graph attention</cite>
             
                 <a href="https://arxiv.org/abs/1710.09599">[arxiv]</a>
             
             
                 <a href="publications/watch_step.pdf">[pdf]</a>
             
             
             <p>
               S Abu-El-Haija, B Perozzi, R Al-Rfou, AA Alemi
               <date>2018-12</date>
               <strong>NeurIPS</strong>
             </p>
             <p>
               Building better graph representations.
             </p>
            </li>
        
            <li>
             <cite>GILBO: one metric to measure them all</cite>
             
                 <a href="https://arxiv.org/abs/1802.04874">[arxiv]</a>
             
             
                 <a href="publications/gilbo.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, I Fischer
               <date>2018-12</date>
               <strong>NeurIPS</strong>
             </p>
             <p>
               A variational lower bound on the mutual informations in GANs highlight some of their problems.
             </p>
            </li>
        
            <li>
             <cite>Fixing a Broken ELBO</cite>
             
                 <a href="https://arxiv.org/abs/1711.00464">[arxiv]</a>
             
             
                 <a href="publications/broken_elbo.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, B Poole, I Fischer, JV Dillon, RA Saurous, K Murphy
               <date>2018-05</date>
               <strong>ICML</strong>
             </p>
             <p>
               Adopting a representational view of VAEs can help explain away some of their problems.
             </p>
            </li>
        
            <li>
             <cite>Tensorflow distributions</cite>
             
                 <a href="https://arxiv.org/abs/1711.10604">[arxiv]</a>
             
             
                 <a href="publications/tfd.pdf">[pdf]</a>
             
             
                 <a href="https://www.tensorflow.org/probability">[code]</a>
             
             <p>
               JV Dillon, I Langmore, D Tran, E Brevdo, S Vasudevan, D Moore, B Patton, AA Alemi, M Hoffman, RA Saurous
               <date>2017-11</date>
               <strong></strong>
             </p>
             <p>
               Paper accompanying library.
             </p>
            </li>
        
            <li>
             <cite>Light microscopy at maximal precision</cite>
             
                 <a href="https://arxiv.org/abs/1702.07336">[arxiv]</a>
             
             
                 <a href="publications/peri.pdf">[pdf]</a>
             
             
             <p>
               M Bierbaum, BD Leahy, AA Alemi, I Cohen, JP Sethna
               <date>2017-02</date>
               <strong>Phys Rev X</strong>
             </p>
             <p>
               Better featuring of colloids.
             </p>
            </li>
        
            <li>
             <cite>Jeffrey's prior sampling of deep sigmoidal networks</cite>
             
                 <a href="https://arxiv.org/abs/1705.10589">[arxiv]</a>
             
             
                 <a href="publications/jeffrey.pdf">[pdf]</a>
             
             
             <p>
               LX Hayden, AA Alemi, PH Ginsparg, JP Sethna
               <date>2017-05</date>
               <strong></strong>
             </p>
             <p>
               Jeffrey's prior doesn't really work for neural networks.
             </p>
            </li>
        
            <li>
             <cite>Motion prediction under multimodality with conditional stochastic networks</cite>
             
                 <a href="https://arxiv.org/abs/1705.02082">[arxiv]</a>
             
             
                 <a href="publications/motion.pdf">[pdf]</a>
             
             
             <p>
               K Fragkiadaki, J Huang, AA Alemi, S Vijayanarasimhan, S Ricco, R Sukthankar
               <date>2017-05</date>
               <strong></strong>
             </p>
             <p>
               Pedestrian motion is stochastic which creates certain challenges.
             </p>
            </li>
        
            <li>
             <cite>Inception-v4, inception-resnet and the impact of residual connections on learning</cite>
             
                 <a href="https://arxiv.org/abs/1602.07261">[arxiv]</a>
             
             
                 <a href="publications/inceptionv4.pdf">[pdf]</a>
             
             
             <p>
               C Szegedy, S Ioffe, V Vanhoucke, AA Alemi
               <date>2017-02</date>
               <strong>AAAI</strong>
             </p>
             <p>
               Residual connections improve the inception family of classifiers.
             </p>
            </li>
        
            <li>
             <cite>Deep Variational Information Bottleneck</cite>
             
                 <a href="https://arxiv.org/abs/1612.00410">[arxiv]</a>
             
             
                 <a href="publications/vib.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, I Fischer, JV Dillon, K Murphy
               <date>2017-03</date>
               <strong>ICLR</strong>
             </p>
             <p>
               A modern formulation of the Information Bottleneck which is friendly towards neural networks.
             </p>
            </li>
        
            <li>
             <cite>Improved generator objectives for gans</cite>
             
                 <a href="https://arxiv.org/abs/1612.02780">[arxiv]</a>
             
             
                 <a href="publications/improved_gan.pdf">[pdf]</a>
             
             
             <p>
               B Poole, AA Alemi, J Sohl-Dickstein, A Angelova
               <date>2016-12</date>
               <strong>NeurIPS Adversarial Workshop</strong>
             </p>
             <p>
               You can target separate divergences for the generator and discriminator of a GAN.
             </p>
            </li>
        
            <li>
             <cite>Tree-Structured Variational Autoencoder</cite>
             
             
                 <a href="publications/tree_vae.pdf">[pdf]</a>
             
             
             <p>
               R Shin, AA Alemi, G Irving, O Vinyals
               <date>2016-11</date>
               <strong></strong>
             </p>
             <p>
               Attempting to learn tree-structured representations.
             </p>
            </li>
        
            <li>
             <cite>Improving inception and image classification in tensorflow</cite>
             
             
             
                 <a href="https://ai.googleblog.com/2016/08/improving-inception-and-image.html">[post]</a>
             
             <p>
               AA Alemi
               <date>2016-06</date>
               <strong>Google Research Blog</strong>
             </p>
             <p>
               Blogpost accompanying open source release of Inception Resnet V2.
             </p>
            </li>
        
            <li>
             <cite>DeepMath-deep sequence models for premise selection</cite>
             
                 <a href="https://arxiv.org/abs/1606.04442">[arxiv]</a>
             
             
                 <a href="publications/deep_math.pdf">[pdf]</a>
             
             
             <p>
               G Irving, C Szegedy, AA Alemi, N Eén, F Chollet, J Urban
               <date>2016-06</date>
               <strong>NeurIPS</strong>
             </p>
             <p>
               Using neural networks to improve automatic theorem proving.
             </p>
            </li>
        
            <li>
             <cite>SPARTA: Fast global planning of collision-avoiding robot trajectories</cite>
             
             
                 <a href="publications/sparta.pdf">[pdf]</a>
             
             
             <p>
               CJM Mathy, F Gonda, D Schmidt, N Derbinsky, AA Alemi, J Bento, FM Delle Fave, JS Yedidia
               <date>2015-12</date>
               <strong></strong>
             </p>
             <p>
               Using ADMM to do fast trajectory planning.
             </p>
            </li>
        
            <li>
             <cite>You can run, you can hide: The epidemiology and statistical mechanics of zombies</cite>
             
                 <a href="https://arxiv.org/abs/1503.01104">[arxiv]</a>
             
             
                 <a href="publications/zombies.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, M Bierbaum, CR Myers, JP Sethna
               <date>2015-11</date>
               <strong>Phys Rev E</strong>
             </p>
             <p>
               A fun pedadogical introduction to epidemiology and statistical mechanics.
             </p>
            </li>
        
            <li>
             <cite>Zombies Reading Segmented Graphene Articles On The Arxiv</cite>
             
             
                 <a href="publications/thesis.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi
               <date>2015-08</date>
               <strong>Thesis</strong>
             </p>
             <p>
               A collection of four of my graduate student projects.
             </p>
            </li>
        
            <li>
             <cite>Clustering via Content-Augmented Stochastic Blockmodels</cite>
             
                 <a href="https://arxiv.org/abs/1505.06538">[arxiv]</a>
             
             
                 <a href="publications/blockmodels.pdf">[pdf]</a>
             
             
             <p>
               JM Cashore, X Zhao, AA Alemi, Y Liu, PI Frazier
               <date>2015-05</date>
               <strong></strong>
             </p>
             <p>
               Better clustering through content conditioning.
             </p>
            </li>
        
            <li>
             <cite>Text segmentation based on semantic word embeddings</cite>
             
                 <a href="https://arxiv.org/abs/1503.05543">[arxiv]</a>
             
             
                 <a href="publications/segmentation.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, P Ginsparg
               <date>2015-03</date>
               <strong></strong>
             </p>
             <p>
               Using word2vec vectors to do automatic text segmentation.
             </p>
            </li>
        
            <li>
             <cite>Mechanical properties of growing melanocytic nevi and the progression to melanoma</cite>
             
                 <a href="https://arxiv.org/abs/1404.4116">[arxiv]</a>
             
             
                 <a href="publications/cancer.pdf">[pdf]</a>
             
             
             <p>
               A Taloni, AA Alemi, E Ciusani, JP Sethna, S Zapperi, CAM La Porta
               <date>2014-04</date>
               <strong>PloS One</strong>
             </p>
             <p>
               Elastic models of skin cancer.
             </p>
            </li>
        
            <li>
             <cite>Ensuring reliability, reproducibility and transferability in atomistic simulations: The knowledgebase of interatomic models (https://openkim.org)</cite>
             
             
                 <a href="publications/openkim-abs.pdf">[pdf]</a>
             
             
             <p>
               E Tadmor, R Elliott, D Karls, A Ludvik, J Sethna, M Bierbaum, AA Alemi, T Wennblom
               <date>2014-10</date>
               <strong></strong>
             </p>
             <p>
               
             </p>
            </li>
        
            <li>
             <cite>Knowledgebase of Interatomic Models application programming interface as a standard for molecular simulations</cite>
             
             
                 <a href="publications/openkim2.pdf">[pdf]</a>
             
             
                 <a href="http://openkim.org">[openkim.org]</a>
             
             <p>
               R Elliott, E Tadmor, D Karls, A Ludvik, J Sethna, M Bierbaum, AA Alemi, T Wennblom
               <date>2014-10</date>
               <strong></strong>
             </p>
             <p>
               Building a website to collect interatomic potentials and score them.
             </p>
            </li>
        
            <li>
             <cite>Imaging atomic rearrangements in two-dimensional silica glass: watching silica's dance</cite>
             
             
                 <a href="publications/glass.pdf">[pdf]</a>
             
             
             <p>
               PY Huang, S Kurasch, JS Alden, A Shekhawat, AA Alemi, PL McEuen, JP Sethna, U Kaiser, DA Muller
               <date>2013-10</date>
               <strong>Science</strong>
             </p>
             <p>
               Applying elastic theory to the atomic scale.
             </p>
            </li>
        
            <li>
             <cite>Growth and form of melanoma cell colonies</cite>
             
                 <a href="https://arxiv.org/abs/1308.6037">[arxiv]</a>
             
             
                 <a href="publications/melanoma.pdf">[pdf]</a>
             
             
             <p>
               MM Baraldi, AA Alemi, JP Sethna, S Caracciolo, CAM La Porta, S Zapperi
               <date>2013-08</date>
               <strong>JSM</strong>
             </p>
             <p>
               Simple models of skin cancer growth.
             </p>
            </li>
        
            <li>
             <cite>Near-field radiative heat transfer between macroscopic planar surfaces</cite>
             
                 <a href="https://arxiv.org/abs/1103.2389">[arxiv]</a>
             
             
                 <a href="publications/heat.pdf">[pdf]</a>
             
             
             <p>
               RS Ottens, Volker Quetschke, Stacy Wise, AA Alemi, Ramsey Lundock, Guido Mueller, David H Reitze, David B Tanner, Bernard F Whiting
               <date>2011-03</date>
               <strong>Phys Rev Lett</strong>
             </p>
             <p>
               Exploration of quantum tunnelling as a mechanism for cooling the next generation LIGO detectors.
             </p>
            </li>
        
            <li>
             <cite>Laplace-Runge-Lenz Vector</cite>
             
             
                 <a href="publications/laplace.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi
               <date>2009-06</date>
               <strong></strong>
             </p>
             <p>
               Undergraduate project on the history of the Runge Vector.
             </p>
            </li>
        
            <li>
             <cite>NEMS Coupling</cite>
             
             
                 <a href="publications/nems.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi
               <date>2008-09</date>
               <strong></strong>
             </p>
             <p>
               Undergraduate research project on synchronization in nano cantilevers.
             </p>
            </li>
        
            <li>
             <cite>Why Venus has no moon</cite>
             
             
                 <a href="publications/venus.pdf">[pdf]</a>
             
             
             <p>
               AA Alemi, DJ Stevenson
               <date>2006-09</date>
               <strong>AAS Oral</strong>
             </p>
             <p>
               Undergraduate research investigating whether two collisions in the opposite direction could explain Venus' lack of moon and slow rotation.
             </p>
            </li>
        
  
        </ul>

    </section>
    <!--- Writings section --->
    <section id="writing">
        <h2><a href="#writing">Writing</a></h2>

        <ul>
        
          
            <li>
             <cite>Why KL?</cite>
             
                 <a href="https://blog.alexalemi.com/kl.html">[Blog]</a>
             
             <p>
               <date>2020-08-07</date>
               Why is the KL divergence so special?
             </p>
            </li>
          
        
          
            <li>
             <cite>Coronavirus Logistic Growth Plots</cite>
             
                 <a href="https://observablehq.com/@alemi/logistic-growth-plots">[Observable]</a>
             
             <p>
               <date>2020-04-13</date>
               A distinct way to view Coronavirus growth.
             </p>
            </li>
          
        
          
            <li>
             <cite>'Live' Logistic Coronavirus Death Counter</cite>
             
                 <a href="https://observablehq.com/@alemi/live-corona-death-counter">[Observable]</a>
             
             <p>
               <date>2020-03-27</date>
               An approximate 'live' corona death counter.
             </p>
            </li>
          
        
          
            <li>
             <cite>Can I compute the mass of a coin based on the sound of its fall?</cite>
             
                 <a href="https://physics.stackexchange.com/questions/121879/can-i-compute-the-mass-of-a-coin-based-on-the-sound-of-its-fall/121932#121932">[Physics Stackexchange]</a>
             
             <p>
               <date>2014-06-26</date>
               Using the sound of coins dropping to predict their values.
             </p>
            </li>
          
        
          
            <li>
             <cite>How effective is speeding?</cite>
             
                 <a href="https://physics.stackexchange.com/questions/123753/how-effective-is-speeding/123760#123760">[Physics Stackexchange]</a>
             
             <p>
               <date>2014-07-09</date>
               A simple model looking at how effective speeding is at saving time and money.
             </p>
            </li>
          
        
          
            <li>
             <cite>Physics of the weird boing sound on racquetball courts.</cite>
             
                 <a href="https://physics.stackexchange.com/questions/127282/physics-of-weird-boing-sound-in-racquetball-courts/127447#127447">[Physics Stackexchange]</a>
             
             <p>
               <date>2014-07-21</date>
               A model that recreates the boing sound.
             </p>
            </li>
          
        
          
            <li>
             <cite>The Linear Theory of Battleship</cite>
             
                 <a href="https://thephysicsvirtuosi.com/posts/old/the-linear-theory-of-battleship/">[The Physics Virtuosi]</a>
             
             <p>
               <date>2011-10-03</date>
               Winning at battleship with a dirt simple model.
             </p>
            </li>
          
        
          
            <li>
             <cite>A tweet is worth at least 140 words</cite>
             
                 <a href="https://thephysicsvirtuosi.com/posts/old/a-tweet-is-worth-at-least-140-words/">[The Physics Virtuosi]</a>
             
             <p>
               <date>2011-08-30</date>
               Greedy twitter compression scheme.
             </p>
            </li>
          
        
          
            <li>
             <cite>How Long Can you Balance A (Quantum) Pencil</cite>
             
                 <a href="https://thephysicsvirtuosi.com/posts/old/how-long-can-you-balance-a-quantum-pencil/">[The Physics Virtuosi]</a>
             
             <p>
               <date>2010-06-16</date>
               Simple and probably wrong calculation for the ultimate length of time a pencil can balance.
             </p>
            </li>
          
        
          
            <li>
             <cite>I was born on Wednesday</cite>
             
                 <a href="https://thephysicsvirtuosi.com/posts/old/i-was-born-on-wednesday/">[The Physics Virtuosi]</a>
             
             <p>
               <date>2010-05-26</date>
               A classic logic puzzle explained.
             </p>
            </li>
          
        
  
        </ul>

    </section>
    <!-- Code projects section -->
    <section id="code">
        <h2><a href="#code">Code</a></h2>

        <p>I've contributed to various Google Opensource projects including: 
        <a href="http://tensorflow.org" target="_blank">TensorFlow</a>,
        <a href="https://www.tensorflow.org/probability" target="_blank">Tensorflow Probability</a>,
        <a href="https://www.tensorflow.org/datasets" target="_blank">Tensorflow Datasets</a>,
        <a href="https://github.com/google/jax" target="_blank">JAX</a>,
        and <a href="https://github.com/google/neural-tangents" target="_blank">Neural Tangents</a>.
        </p>

        <p>I also opensourced a top class image classification network: <a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py" target="_blank">Inception Resnet V2</a>.
        </p>

        <p><a href="https://github.com/pychebfun" target="_blank">pychebfun</a> is 
        an open source reimplimentation of <a href="http://chebfun.org" target="_blank">ChebFun</a>.
        </p>

        <p><a href="https://texpad.alexalemi.com">texpad.alexalemi.com</a> is a simple
        static MathJAX formula as copyable image generator.
        </p>
        


    </section>

    <!-- Talks section -->
    <section id="talks">
        <h2><a href="#talks">Talks</a></h2>
        <ul>

          
              <li>
                <cite>VIB is Half Bayes</cite>
                
                    
                        <a href="https://youtu.be/GVMmou2-zdk" >[poster]</a>
                    
                
                    
                        <a href="talks/vib-is-half-bayes.html" >[talk]</a>
                    
                
                <p>
                  <date>2021-02</date>
                  <strong>Advances in Approximate Bayesian Inference Symposium 2021</strong>
                </p>
                <p>
                  The Variational Information Bottleneck can be viewed as a sort of half-Bayesian approach.
                </p>
              </li>
          
              <li>
                <cite>Machine Learning and Thermodynamics</cite>
                
                    
                        <a href="https://umd.zoom.us/rec/play/HzmmQWvPH60zxHaOCHAy6Uwt3UUJWfZYB-YA007p6KHTOY56BXYpCtP-EZAosMIaVgVyja9DXsdpf39w.RV77En0w92lneh-v?continueMode=true&_x_zm_rtaid=uqeY5cMmQbe7o5ux5nhmdw.1605629917876.6f991d113b88c5fff5356c5d0db95d7f&_x_zm_rhtaid=693" >[video]</a>
                    
                
                    
                        <a href="talks/ml-and-thermo.html" >[slides]</a>
                    
                
                <p>
                  <date>2020-06</date>
                  <strong>University of Maryland - Informal Statistical Physics Seminar</strong>
                </p>
                <p>
                  Thermodynamics from a Probabilistic perspective and machine learning from a thermodynamic perspective.
                </p>
              </li>
          
              <li>
                <cite>TherML</cite>
                
                    
                        <a href="https://www.youtube.com/watch?v=jG4pqVqUCdw" >[video]</a>
                    
                
                    
                        <a href="talks/therml-aps.html" >[slides]</a>
                    
                
                <p>
                  <date>2020-06</date>
                  <strong>American Physical Society Topical Group on Data Science</strong>
                </p>
                <p>
                  Another version of my TherML talk.
                </p>
              </li>
          
              <li>
                <cite>Variational Predictive Information Bottleneck</cite>
                
                    
                        <a href="talks/ita-pib.html" >[slides]</a>
                    
                
                <p>
                  <date>2020-02</date>
                  <strong>Information Theory and Applications Workshop</strong>
                </p>
                <p>
                  I attempt to show that most modern forms of inference can be viewed as optimizing a variational bound on a predictive information bottleneck objective.
                </p>
              </li>
          
              <li>
                <cite>A Case for Compression</cite>
                
                    
                        <a href="https://slideslive.com/38921970" >[video starts @ 25:30]</a>
                    
                
                    
                        <a href="talks/case-for-compression.html" >[slides]</a>
                    
                
                <p>
                  <date>2019-12</date>
                  <strong>NeurIPS 2019 Workshop on Information Theory and Machine Learning</strong>
                </p>
                <p>
                  I offer arguments both for and against learning compressed representations in the form of a generalized information bottleneck.
                </p>
              </li>
          
              <li>
                <cite>TherML</cite>
                
                    
                        <a href="talks/therml.html" >[slides]</a>
                    
                
                <p>
                  <date>2019-01</date>
                  <strong>Aspen: Machine Learning and Physics</strong>
                </p>
                <p>
                  Drawing an analogy between Thermodynamics and modern deep variational latent variable generative modelling
                </p>
              </li>
          
              <li>
                <cite>Focusing on the Representation</cite>
                
                    
                        <a href="talks/focusing-on-the-representation.html" >[slides]</a>
                    
                
                <p>
                  <date>2018-11</date>
                  <strong>Cornell AI Seminar</strong>
                </p>
                <p>
                  An overview of my work, which often amounts to reinterpreting existing techniques in a representational light.
                </p>
              </li>
          
              <li>
                <cite>Thermodynamics and Machine Learning</cite>
                
                    
                        <a href="talks/thermodynamics-and-ml.html" >[slides]</a>
                    
                
                <p>
                  <date>2018-11</date>
                  <strong>Cornell Physics Colloquium</strong>
                </p>
                <p>
                  An earlier talk relating thermodynamics and machine learning for a physics audience.
                </p>
              </li>
          
              <li>
                <cite>Fixing a BrokenELBO</cite>
                
                    
                        <a href="talks/fixing-broken-elbo.html" >[slides]</a>
                    
                
                <p>
                  <date>2018-07</date>
                  <strong>ICML2018</strong>
                </p>
                <p>
                  A representational reinterpretation of VAEs that help clarify issues such as posterior collapse.
                </p>
              </li>
          
              <li>
                <cite>Uncertainty in VIB</cite>
                
                    
                        <a href="talks/uaivib.html" >[slides]</a>
                    
                
                <p>
                  <date>2018-08</date>
                  <strong>UAI UDL Workshop 2018</strong>
                </p>
                <p>
                  VIB classifiers capture uncertainty effectively.
                </p>
              </li>
          

        </ul>
    </section>

    <!-- Poster presentations section -->
    <!-- <section>
        <h2><a href="#poster-presentations" style="text-decoration: none;" id="poster-presentations">#</a> Poster Presentations</h2>


        <p><a href="http://colinraffel.com/posters/iclr2019understanding.pdf">Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer</a> at 7th International Conference on Learning Representations, 2019.</p>

    </section> -->


    <!-- Etc. section -->
    <section id="etc">
        <h2><a href="#etc">Etc.</a></h2>

        <ul>

          <li><p>I used to be quite active on the <a href="https://physics.stackexchange.com/users/51994/alemi">Physics Stackexchange</a>.
        </p>

        <li><p><a href="https://espdic.alexalemi.com">Espdic</a> is a simple Esperanto Dictionary.</p>

        <li><p><a href="http://mattbierbaum.github.io/onelook/">One Look</a>: A ludum dare 45 entry.</p>

        <li><p>A <a href="https://mattbierbaum.github.io/zombies-usa/">Zombie Simulator</a> for our paper.</p>

        <li><p><a href="http://thephysicsvirtuosi.com">The Physics Virtuosi</a> 
        was a blog I ran with some friends from graduate school.
        </p>

        <li><p><a href="http://pages.physics.cornell.edu/~aalemi/">My Old Homepage</a> 
        at Cornell University has some random things.
        </p>

        </ul>

    </section>

    <!-- MathJax -->
    <!-- 
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    -->

</body>
</html>